{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.nn as nn\nfrom zipfile import ZipFile\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport matplotlib.pyplot as plt\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nimport torchvision\nimport zipfile\nfrom IPython import display\nfrom torch.autograd import Function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = []\n# r=root, d=directories, f = files\nfor r, d, f in os.walk('../input'):\n    for file in f:\n        if '.png' in file:\n            files.append(os.path.join(r, file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class myDataset(Dataset):\n    def __init__(self,path = '../input'):\n        super(myDataset, self).__init__()\n        self.files = []\n        for r, d, f in os.walk(path):\n            for file in f:\n                if '.png' in file:\n                    self.files.append(os.path.join(r, file))\n\n    def __getitem__(self,idx):\n        img = Image.open(self.files[idx])\n        return self.transform(img)\n    def __len__(self):\n        return len(self.files)\n    def transform(self,img):\n        if random.random()>0.5:\n            angle = random.randint(-60, 60)\n            img = TF.rotate(img,angle)\n        width, height = img.size\n        dw = 32 - (width%32)\n        dh = 32 - (height%32)\n        img = TF.pad(img,(dw,dh,0,0))\n        return TF.to_tensor(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = myDataset()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SignFunction(Function):\n    def __init__(self):\n        super(SignFunction,self).__init__()\n    @staticmethod\n    def forward(ctx,input, is_training=True):\n        if is_training:\n            prob = input.new(input.size()).uniform_()\n            x = input.clone()\n            x[(1 - input) / 2 <= prob] = 1\n            x[(1 - input) / 2 > prob] = -1\n            return x\n        else:\n            return input.sign()\n    @staticmethod\n    def backward(ctx, grad_output):\n        return grad_output, None\n        \nclass Sign(nn.Module):\n    def __init__(self):\n        super(Sign, self).__init__()\n    def forward(self,x):\n        return SignFunction.apply(x, self.training)\nclass Binarizer(nn.Module):\n    def __init__(self,in_channels,out_channels):\n        super(Binarizer,self).__init__()\n        self.sign = Sign()\n        self.conv1 = nn.Conv2d(in_channels, out_channels,kernel_size=1,bias=False)\n    def forward(self,x):\n        x = self.conv1(x)\n        x =  F.tanh(x)\n        return self.sign(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class autoencoder(nn.Module):\n    def __init__(self):\n        super(autoencoder,self).__init__()\n        self.enc = nn.Sequential(nn.Conv2d(3,32,8,stride=4,padding=2),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(32),\n                                nn.Conv2d(32,64,2,stride=2),\n                                nn.ReLU(),\n                                nn.BatchNorm2d(64),\n                                )\n        self.dec = nn.Sequential(nn.ConvTranspose2d(128,32,8,stride=4, padding=2),\n                                nn.BatchNorm2d(32),\n                                nn.ReLU(),\n                                nn.ConvTranspose2d(32,3,2,2),\n                                nn.BatchNorm2d(3),\n                                nn.ReLU(),\n                                )\n        self.binarizer = Binarizer(64,128)\n    def forward(self,x):\n    \n        x = self.enc(x)\n        x = self.binarizer(x)\n        x = self.dec(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1\nvalidation_split = 0.1\nshuffle_dataset = True\nrandom_seed= 42\n\nds = myDataset()\n\n# Creating data indices for training and validation splits:\ndataset_size = len(ds)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalidation_sampler = SubsetRandomSampler(val_indices)\ntrain_loader = torch.utils.data.DataLoader(ds,batch_size=batch_size,sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(ds, batch_size=batch_size,sampler=validation_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=autoencoder().float()\ncriterion =  nn.SmoothL1Loss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\nexp_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,80,100], gamma=0.1)\nif torch.cuda.is_available():\n    model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(epoch=1):\n    while epoch<=stop_epoch:\n        total_loss = 0\n        total_accuracy = 0\n        model.train()\n        exp_lr_scheduler.step()\n        print('Epoch: {}\\tLR: {:.5f}'.format(epoch,exp_lr_scheduler.get_lr()[0]))\n        for batch_idx, data in enumerate(train_loader):\n          target = data\n          if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n          # forward\n          output = model(data)\n    #       print(output.shape)\n    #       print(data.shape)\n          # backward + optimize\n          loss = criterion(output, target)\n          optimizer.zero_grad()\n          loss.backward()\n          optimizer.step()\n          # print statistics\n          accuracy = 0\n          total_accuracy+=accuracy\n          total_loss+=loss\n    #       print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}'.format(epoch, (batch_idx + 1) * len(data), len(train_indices),100*(batch_idx + 1)* len(data) / len(train_indices), loss))\n        print('Train Loss: \\t'+str(total_loss*batch_size/len(train_indices)))\n        vloss, vaccuracy = validate()\n        train_losses.append((total_loss*batch_size)/len(train_indices))\n        val_losses.append((vloss*batch_size)/len(val_indices))\n        train_accuracy.append((total_accuracy*batch_size)/len(train_indices))\n        val_accuracy.append((vaccuracy*batch_size)/len(val_indices))\n        epoch_data.append(epoch)\n        visualize()\n        epoch=1+epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate():\n  total_loss = 0\n  total_acc = 0\n  model.train()\n  for batch_idx, data in enumerate(validation_loader):\n    target = data\n    if torch.cuda.is_available():\n      data = data.cuda()\n      target = target.cuda()\n    output = model(data)\n    loss = criterion(output, target).item()\n#     optimizer.zero_grad()\n#     loss.backward()\n#     optimizer.step()\n    total_loss+=loss\n    accuracy = 0\n    total_acc+=accuracy\n  return total_loss,total_acc\ndef visualize():\n  plt.figure(figsize=(15,7))\n  plt.plot(epoch_data, train_losses,label=\"Train Loss {:.5f}\".format(train_losses[-1]))\n  plt.plot(epoch_data,val_losses, label=\"Validation Loss {:.5f}\".format(val_losses[-1]))\n  plt.plot(epoch_data, train_accuracy,label=\"Train Accuracy {:.5f}\".format(train_accuracy[-1]))\n  plt.plot(epoch_data,val_accuracy, label=\"Validation Accuracy {:.5f}\".format(val_accuracy[-1]))\n  display.clear_output(wait=False)\n  plt.legend()\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_losses = []\nval_losses = []\nepoch_data = []\ntrain_accuracy = []\nval_accuracy = []\nstop_epoch = 52\nstart = time.time()\ntrain()\nend = time.time()\nprint(end-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}